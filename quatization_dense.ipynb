{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notobook simply demonstrades how to perform the Post-Traning-Quantization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import random\n",
    "random.seed(42)\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:   print(e)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the data (between 0 and 1)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Reshaped data to match the input shape of the Conv2D layer\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dense Layer\n",
    "class CustomDense(Layer):\n",
    "    def __init__(self, units, activation=None, quantized_type=tf.int8, quantized_technique='asymmetric'):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.quantized_type = quantized_type\n",
    "        self.quantized_technique = quantized_technique  # symmetric or asymmetric\n",
    "\n",
    "    def get_symmetric_quantize_matrix(self, x, target_dtype):\n",
    "        # Define the range for target type\n",
    "        qmin = tf.constant(target_dtype.min, dtype=tf.float32)\n",
    "        qmax = tf.constant(target_dtype.max, dtype=tf.float32)\n",
    "\n",
    "        # Compute the scale factor\n",
    "        max_abs_val = tf.reduce_max(tf.abs(x))\n",
    "        scale = max_abs_val / qmax\n",
    "        zero_point = 0.0\n",
    "\n",
    "        # Quantization and Clip to ensure quantized values are within the range\n",
    "        quantized = tf.round(x / scale)  # Perform quantization\n",
    "        quantized = tf.clip_by_value(quantized, qmin, qmax) \n",
    "        \n",
    "        return tf.cast(quantized, target_dtype), scale, zero_point\n",
    "\n",
    "\n",
    "    def get_asymmetric_quantize_matrix(self, x, target_dtype):\n",
    "        # Define the range for the target type\n",
    "        qmin = tf.constant(target_dtype.min, dtype=tf.float32)\n",
    "        qmax = tf.constant(target_dtype.max, dtype=tf.float32)\n",
    "        \n",
    "        # Compute the min and max for the actual tensor\n",
    "        x_min = tf.reduce_min(x)\n",
    "        x_max = tf.reduce_max(x)\n",
    "\n",
    "        # Scale and zero point calculations\n",
    "        scale = (x_max - x_min) / (qmax - qmin)\n",
    "        zero_point = tf.cast(qmin - x_min / scale, tf.float32)\n",
    "\n",
    "        # Quantization and Clip to ensure quantized values are within the range\n",
    "        quantized = tf.round((x - x_min) / scale + qmin)\n",
    "        quantized = tf.clip_by_value(quantized, qmin, qmax)\n",
    "\n",
    "        return tf.cast(quantized, target_dtype), scale, zero_point\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initialize weights and bias\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "        self.w_quantized = self.add_weight(shape=(input_shape[-1], self.units), dtype=self.quantized_type, initializer='zeros', trainable=False)\n",
    "        self.quantized_scale = self.add_weight(shape=(), initializer='ones', trainable=False)\n",
    "        self.zero_point = self.add_weight(shape=(), initializer='ones', trainable=False)\n",
    "\n",
    "        super(CustomDense, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "\n",
    "    def post_training_quantization(self):\n",
    "        \"\"\"Perform post training quantization after FINISH training\"\"\"\n",
    "\n",
    "        # Query matrix\n",
    "        if self.quantized_technique == 'symmetric':\n",
    "            w_quantized, quantized_scale, zero_point = self.get_symmetric_quantize_matrix(self.w, target_dtype=self.quantized_type)\n",
    "        elif self.quantized_technique == 'asymmetric':\n",
    "            w_quantized, quantized_scale, zero_point = self.get_asymmetric_quantize_matrix(self.w, target_dtype=self.quantized_type)\n",
    "\n",
    "        self.w_quantized.assign(w_quantized)\n",
    "        self.quantized_scale.assign(quantized_scale)\n",
    "        self.zero_point.assign(zero_point)\n",
    "\n",
    "        del self.w\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # Linear transformation\n",
    "        if hasattr(self, 'w'):\n",
    "            z = tf.matmul(inputs, self.w) + self.b  # Linear transformation\n",
    "        else:\n",
    "            w_dequantized = tf.cast(self.w_quantized, tf.float32) - self.zero_point\n",
    "            w_dequantized = tf.multiply(w_dequantized, self.quantized_scale)\n",
    "            z = tf.matmul(inputs, w_dequantized) + self.b\n",
    "\n",
    "        if self.activation:\n",
    "            z = self.activation(z)  \n",
    "        return z  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " custom_dense (CustomDense)  (None, 128)               200834    \n",
      "                                                                 \n",
      " custom_dense_1 (CustomDens  (None, 10)                2572      \n",
      " e)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203406 (496.80 KB)\n",
      "Trainable params: 101770 (397.54 KB)\n",
      "Non-trainable params: 101636 (99.27 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Flatten 28x28 images to 1D vectors\n",
    "    CustomDense(128, activation='relu'),  # Add a fully connected layer\n",
    "    CustomDense(10, activation='softmax') # Output layer with 10 neurons for classification\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post_Quantization_Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(Post_Quantization_Callback, self).__init__()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.quantization_layer()\n",
    "\n",
    "    def quantization_layer(self):\n",
    "        for layer in self.model.submodules:\n",
    "            if isinstance(layer, CustomDense):\n",
    "                layer.post_training_quantization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 590us/step - loss: 0.2878 - accuracy: 0.9207\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 574us/step - loss: 0.1230 - accuracy: 0.9639\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 566us/step - loss: 0.0827 - accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 574us/step - loss: 0.0625 - accuracy: 0.9811\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 575us/step - loss: 0.0488 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1498124970>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    Post_Quantization_Callback()\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " custom_dense (CustomDense)  (None, 128)               100482    \n",
      "                                                                 \n",
      " custom_dense_1 (CustomDens  (None, 10)                1292      \n",
      " e)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101774 (99.80 KB)\n",
      "Trainable params: 138 (552.00 Byte)\n",
      "Non-trainable params: 101636 (99.27 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 552us/step - loss: 0.0763 - accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0762646421790123, 0.9775999784469604]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
