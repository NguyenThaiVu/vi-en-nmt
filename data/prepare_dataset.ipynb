{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, I will prepare the dataset:\n",
    "- Split `pho_mt` dataset into train set (80) and test set (20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import regex as re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_EN_PHO_MT_FILE = r\"processed_data/pho_mt_en_sent.txt\"\n",
    "PATH_VI_PHO_MT_FILE = r\"processed_data/pho_mt_vi_sent.txt\"\n",
    "\n",
    "PATH_FOLDER_PROCESS = \"processed_data\"\n",
    "\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pair sentence: 3010915\n"
     ]
    }
   ],
   "source": [
    "list_en_sentence = read_text_file(PATH_EN_PHO_MT_FILE)\n",
    "list_vi_sentence = read_text_file(PATH_VI_PHO_MT_FILE)\n",
    "assert len(list_en_sentence) == len(list_vi_sentence)\n",
    "\n",
    "print(f\"Number of pair sentence: {len(list_en_sentence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: mark zuckerberg wants to create a global community .\n",
      "Vietname: mark zuckerberg muốn tạo ra một cộng đồng toàn cầu .\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(list_en_sentence))\n",
    "\n",
    "en_sentence = list_en_sentence[idx]\n",
    "vi_sentence = list_vi_sentence[idx]\n",
    "\n",
    "print(f\"English: {en_sentence}\")\n",
    "print(f\"Vietname: {vi_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_en_sentence_train, list_en_sentence_test, list_vi_sentence_train, list_vi_sentence_test = \\\n",
    "    train_test_split(list_en_sentence, list_vi_sentence, test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pair train sentence: 2408732\n",
      "Number of pair test sentence: 602183\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pair train sentence: {len(list_en_sentence_train)}\")\n",
    "print(f\"Number of pair test sentence: {len(list_en_sentence_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Number of words\n",
    "\n",
    "In this section, we will explore the number of words in English corpus and Vietnamese corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word in English vocab: 416448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xiangkhouang',\n",
       " 'schpielt',\n",
       " 'houria',\n",
       " 'santander\")',\n",
       " 'dadaratatatah',\n",
       " '11february',\n",
       " 't25%',\n",
       " '(kaigun',\n",
       " 'ninkasi',\n",
       " \"'bila\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab = get_vocab_from_list_sentence(list_en_sentence_train)\n",
    "print(f\"Number of word in English vocab: {len(en_vocab)}\")\n",
    "en_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word in Vietnamese vocab: 345761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['schpielt',\n",
       " 'houria',\n",
       " 'santander\")',\n",
       " 'dadaratatatah',\n",
       " 'mgsa-α)',\n",
       " '(kaigun',\n",
       " 'ninkasi',\n",
       " \"tụ'\",\n",
       " '(\"log\")',\n",
       " \"'bila\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_vocab = get_vocab_from_list_sentence(list_vi_sentence_train)\n",
    "print(f\"Number of word in Vietnamese vocab: {len(vi_vocab)}\")\n",
    "vi_vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sentences_to_file(list_en_sentence_train, os.path.join(PATH_FOLDER_PROCESS, \"en_sent_train.txt\"))\n",
    "save_sentences_to_file(list_vi_sentence_train, os.path.join(PATH_FOLDER_PROCESS, \"vi_sent_train.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sentences_to_file(list_en_sentence_test, os.path.join(PATH_FOLDER_PROCESS, \"en_sent_test.txt\"))\n",
    "save_sentences_to_file(list_vi_sentence_test, os.path.join(PATH_FOLDER_PROCESS, \"vi_sent_test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thaivu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
