{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, we will explore the raw en-vi dataset.\n",
    "\n",
    "Currently, we use the list of dataset: \n",
    "- English Vietnamese Translation (envitrans). Link: https://www.kaggle.com/datasets/flightstar/english-vietnamese-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import regex as re\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.read_file_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_EN_FILE = r\"raw_data/envitrans/en_sents\"\n",
    "PATH_VI_FILE = r\"raw_data/envitrans/vi_sents\"\n",
    "\n",
    "PATH_FOLDER_PROCESS = r\"processed_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_en_sentence = read_text_file(PATH_EN_FILE)\n",
    "list_vi_sentence = read_text_file(PATH_VI_FILE)\n",
    "\n",
    "assert len(list_en_sentence) == len(list_vi_sentence)\n",
    "print(f\"Number of pair sentence: {len(list_en_sentence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(list_en_sentence))\n",
    "\n",
    "en_sentence = list_en_sentence[idx]\n",
    "vi_sentence = list_vi_sentence[idx]\n",
    "\n",
    "print(f\"English: {en_sentence}\")\n",
    "print(f\"Vietname: {vi_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Average length sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_en_sentence = [get_len_sentence(en_sentence) for en_sentence in list_en_sentence]\n",
    "len_en_sentence = np.array(len_en_sentence)\n",
    "\n",
    "print(f\"Max english sentence length: {len_en_sentence.max()}\")\n",
    "print(f\"Min english sentence length: {len_en_sentence.min()}\")\n",
    "print(f\"Mean english sentence length: {len_en_sentence.mean()}\")\n",
    "\n",
    "plt.title(\"Histogram of english sentence length\")\n",
    "plt.hist(len_en_sentence, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_vi_sentence = [get_len_sentence(vi_sentence) for vi_sentence in list_vi_sentence]\n",
    "len_vi_sentence = np.array(len_vi_sentence)\n",
    "\n",
    "print(f\"Max Vietnamese sentence length: {len_vi_sentence.max()}\")\n",
    "print(f\"Min Vietnamese sentence length: {len_vi_sentence.min()}\")\n",
    "print(f\"Mean Vietnamese sentence length: {len_vi_sentence.mean()}\")\n",
    "\n",
    "plt.title(\"Histogram of Vietnamese sentence length\")\n",
    "plt.hist(len_vi_sentence, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Number of words\n",
    "\n",
    "In this section, we will explore the number of words in English corpus and Vietnamese corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = get_vocab_from_list_sentence(list_en_sentence)\n",
    "print(f\"Number of word in English vocab: {len(en_vocab)}\")\n",
    "en_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_vocab = get_vocab_from_list_sentence(list_vi_sentence)\n",
    "print(f\"Number of word in Vietnamese vocab: {len(vi_vocab)}\")\n",
    "vi_vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Process dataset\n",
    "\n",
    "In this section, we will format sentence with the following criteria:\n",
    "- Convert to lowercase.\n",
    "- Add spaces around punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_en_sentence = [format_sentence(en_sentence) for en_sentence in list_en_sentence]\n",
    "list_vi_sentence = [format_sentence(vi_sentence) for vi_sentence in list_vi_sentence]\n",
    "\n",
    "assert len(list_en_sentence) == len(list_vi_sentence)\n",
    "print(f\"Number of pair sentence: {len(list_en_sentence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(list_en_sentence))\n",
    "\n",
    "en_sentence = list_en_sentence[idx]\n",
    "vi_sentence = list_vi_sentence[idx]\n",
    "\n",
    "print(f\"English: {en_sentence}\")\n",
    "print(f\"Vietname: {vi_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Save process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sentences_to_file(list_en_sentence, os.path.join(PATH_FOLDER_PROCESS, \"envitrans_en_sent.txt\"))\n",
    "save_sentences_to_file(list_vi_sentence, os.path.join(PATH_FOLDER_PROCESS, \"envitrans_vi_sent.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
